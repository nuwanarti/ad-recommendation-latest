<html>

<head>
    <script src="https://download.affectiva.com/js/3.2.1/affdex.js"> </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <!-- <script src="./css/bootstrap-theme.min.css"></script> -->
    <!-- <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css"
        integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous"> -->

    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">

</head>

<body style="background: black;">

    <nav>
        <div class="nav nav-tabs" id="nav-tab" role="tablist">
            <button class="nav-link active" id="nav-home-tab" data-bs-toggle="tab" data-bs-target="#nav-home"
                type="button" role="tab" aria-controls="nav-home" aria-selected="true"
                onclick="setRequestType('demography')">Demography</button>
            <button class="nav-link" id="nav-profile-tab" data-bs-toggle="tab" data-bs-target="#nav-profile"
                type="button" role="tab" aria-controls="nav-profile" aria-selected="false"
                onclick="setRequestType('facialFeatures')">Emotions and Facial Features</button>
            <button class="nav-link" id="nav-contact-tab" data-bs-toggle="tab" data-bs-target="#nav-contact"
                type="button" role="tab" aria-controls="nav-contact" aria-selected="false"
                onclick="setRequestType('ensemble')">Ensemble</button>
        </div>
    </nav>
    <div class="tab-content" id="nav-tabContent">
        <div class="tab-pane fade show active" id="nav-home" role="tabpanel" aria-labelledby="nav-home-tab">...</div>
        <div class="tab-pane fade" id="nav-profile" role="tabpanel" aria-labelledby="nav-profile-tab">...</div>
        <div class="tab-pane fade" id="nav-contact" role="tabpanel" aria-labelledby="nav-contact-tab">...</div>
    </div>

    <div class="container-fluid">
        <div id="adDiv" class="row"
            style="display: none; position: fixed; top: 0px; left: 0px; z-index: 1000; width:100%; height: 100%;">
            <div class="col-xs-12" style="background-color: rgba(0, 0, 0, 0.5); height: 1000px">
                <div id="adPlayer"></div>
            </div>
        </div>
        <div class="row">
            <div class="col-xs-6">
                <!-- <iframe id="video" width="950" height="500" src="https://www.youtube.com/embed/45xuJKYeGW0"
                    title="YouTube video player" frameborder="0"
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen></iframe> -->
                <div id="player"></div>
            </div>
            <div class="col-xs-4">
                <div id="affdex_elements"></div>
                <div>
                    <button id="start" onclick="onStart()">Start</button>
                    <button id="stop" onclick="onStop()">Stop and Submit</button>
                    <button id="reset" onclick="onReset()">Reset</button>
                    <input id="userId" value="" placeholder="Please enter user id" />
                    <h2 id="score"></h2>
                </div>
            </div>
            <div class="col-xs-2">
                <strong>DETECTOR LOG MSGS</strong>
                <div id="logs"></div>
            </div>
        </div>

    </div>
    <div class="row">

        <div class="col-xs-12">
            <div style="height:25em;">
                <strong>EMOTION TRACKING RESULTS</strong>
                <div id="results" style="word-wrap:break-word;"></div>
            </div>
            <div>

            </div>
            <div id="logs"></div>
        </div>
    </div>

    <div>

    </div>
    </div>
    <!-- bootstrap js -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
        crossorigin="anonymous"></script>

</body>

<script>

    var adId = ''
    var adPlayer;
    var interval = setInterval(() => {
        getAdUrl()

    }, 60000)

    function playAd() {
        console.log('play ad')
        $('#adDiv').css('display', 'block')
        adPlayer.loadVideoById(adId,
                     5)
        try{
            adPlayer.playVideo()
        }catch(e){
            console.log('thrown')
            console.log(e)
        }
        
        setTimeout(() => {
            adPlayer.stopVideo()
            stopAd()
            player.playVideo()
            interval = setInterval(() => {
                getAdUrl()

            }, 60000)
        }, 28000)


    }

    function getAdUrl() {

        clearInterval(interval)

        $.ajax({
            // url: 'https://backend.in.ngrok.io/emotions',
            url: 'http://localhost:3210/getAdUrl',
            type: 'POST',
            data: JSON.stringify({
                faceParams: faceParams,
                demography: demography,
                type: rqType,
                userId: $('#userId').val()
            }),
            contentType: 'application/json; charset=utf-8',
            success: function (data) {
                console.log(data);
                // alert(JSON.stringify(data))
                adId = data.data
                // $('#score').html(data.mean)
                player.pauseVideo()
                playAd()
            },
        })
    }

    function stopAd() {

        $('#adDiv').css('display', 'none')

    }
    // 2. This code loads the IFrame Player API code asynchronously.
    var tag = document.createElement('script');

    tag.src = "https://www.youtube.com/iframe_api";
    var firstScriptTag = document.getElementsByTagName('script')[0];
    firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

    // 3. This function creates an <iframe> (and YouTube player)
    //    after the API code downloads.
    var player;

    function onYouTubeIframeAPIReady() {
        player = new YT.Player('player', {
            height: '500',
            width: '950',
            videoId: '45xuJKYeGW0',
            playerVars: {
                'playsinline': 1
            },
            events: {
                'onReady': onPlayerReady,
                'onStateChange': onPlayerStateChange
            }
        });

        adPlayer = new YT.Player('adPlayer', {
            height: '500',
            width: '950',
            videoId: adId, // ad video id
            playerVars: {
                'playsinline': 1
            },
            events: {
                'onReady': onPlayerReady,
                'onStateChange': onPlayerStateChange,
                // 'on'
            }
        });
    }

    // 4. The API will call this function when the video player is ready.
    function onPlayerReady(event) {
        event.target.playVideo();
    }

    // 5. The API calls this function when the player's state changes.
    //    The function indicates that when playing a video (state=1),
    //    the player should play for six seconds and then stop.
    var done = false;
    function onPlayerStateChange(event) {
        // if (event.data == YT.PlayerState.PLAYING && !done) {
        //     setTimeout(stopVideo, 6000);
        //     done = true;
        // }
    }
    function stopVideo() {
        player.stopVideo();
    }

    var detector = null;
    let faceParams = []
    let demography = []
    let isOk = false;
    let rqType = 'demography'

    $(document).ready(function () {
        console.log('ran')
        // SDK Needs to create video and canvas nodes in the DOM in order to function
        // Here we are adding those nodes a predefined div.
        var divRoot = $("#affdex_elements")[0];
        // var divRoot = Document.getElementById('#affdex_elements')
        var width = 640;
        var height = 480;
        var faceMode = affdex.FaceDetectorMode.LARGE_FACES;
        //Construct a CameraDetector and specify the image width / height and face detector mode.
        detector = new affdex.CameraDetector(divRoot, width, height, faceMode);

        //Enable detection of all Expressions, Emotions and Emojis classifiers.
        detector.detectAllEmotions();
        detector.detectAllExpressions();
        detector.detectAllEmojis();
        detector.detectAllAppearance();

        //Add a callback to notify when the detector is initialized and ready for runing.
        detector.addEventListener("onInitializeSuccess", function () {
            log('#logs', "The detector reports initialized");
            //Display canvas instead of video feed because we want to draw the feature points on it
            $("#face_video_canvas").css("display", "block");
            $("#face_video").css("display", "none");
        });

        //Add a callback to notify when camera access is allowed
        detector.addEventListener("onWebcamConnectSuccess", function () {
            log('#logs', "Webcam access allowed");
        });

        //Add a callback to notify when camera access is denied
        detector.addEventListener("onWebcamConnectFailure", function () {
            log('#logs', "webcam denied");
            console.log("Webcam access denied");
            console.log(detector)
            // detector = new affdex.CameraDetector(divRoot, width, height, faceMode);
        });

        //Add a callback to notify when detector is stopped
        detector.addEventListener("onStopSuccess", function () {
            log('#logs', "The detector reports stopped");
            $("#results").html("");
        });

        //Add a callback to receive the results from processing an image.
        //The faces object contains the list of the faces detected in an image.
        //Faces object contains probabilities for all the different expressions, emotions and appearance metrics
        detector.addEventListener("onImageResultsSuccess", function (faces, image, timestamp) {
            $('#results').html("");
            log('#results', "Timestamp: " + timestamp.toFixed(2));
            log('#results', "Number of faces found: " + faces.length);
            if (faces.length > 0) {
                let face = {
                    ...(faces[0].expressions),
                    ...(faces[0].emotions),
                    timestamp: Date.now()
                }
                faceParams.push(face);
                if (demography.length != faces.length) {
                    faces.forEach((f, i) => {
                        // (f.appearance.gender == 'Male' || f.appearance.gender == 'Female')
                        if (f.appearance.gender != 'Unknown' && f.appearance.age != 'Unknown') {
                            demography[i] = {
                                gender: f.appearance.gender == 'Male' ? 1 : 0,
                                age: getAgeCategory(f.appearance.age)
                            }
                        }
                    })
                    if (faces.length == demography.length) {
                        isOk = true
                    }
                }
                log('#results', "Appearance: " + JSON.stringify(faces[0].appearance));
                log('#results', "Emotions: " + JSON.stringify(faces[0].emotions, function (key, val) {
                    return val.toFixed ? Number(val.toFixed(0)) : val;
                }));
                log('#results', "Expressions: " + JSON.stringify(faces[0].expressions, function (key, val) {
                    return val.toFixed ? Number(val.toFixed(0)) : val;
                }));
                log('#results', "Emoji: " + faces[0].emojis.dominantEmoji);
                drawFeaturePoints(image, faces[0].featurePoints);
            }
        });

        function getAgeCategory(cat) {
            let ages = cat.replaceAll(' ', '').split('-').map(a => parseInt(a))
            let a = (ages[0] + ages[1]) / 2
            if (a >= 5 && a < 19)
                return 0
            else if (a >= 19 && a < 35)
                return 1
            else if (a >= 35 && a < 55)
                return 2
            else if (a >= 55 && a < 100)
                return 3
            else
                return 3
        }

        //Draw the detected facial feature points on the image
        function drawFeaturePoints(img, featurePoints) {
            var contxt = $('#face_video_canvas')[0].getContext('2d');

            var hRatio = contxt.canvas.width / img.width;
            var vRatio = contxt.canvas.height / img.height;
            var ratio = Math.min(hRatio, vRatio);

            contxt.strokeStyle = "#FFFFFF";
            for (var id in featurePoints) {
                contxt.beginPath();
                contxt.arc(featurePoints[id].x,
                    featurePoints[id].y, 2, 0, 2 * Math.PI);
                contxt.stroke();

            }
        }

    });

    function setRequestType(type) {

        rqType = type
    }

    function log(node_name, msg) {
        $(node_name).append("<span>" + msg + "</span><br />")
    }

    //function executes when Start button is pushed.
    function onStart() {
        if (detector && !detector.isRunning) {
            $("#logs").html("");
            detector.start();
        }
        log('#logs', "Clicked the start button");
    }

    //function executes when the Stop button is pushed.
    function onStop() {
        log('#logs', "Clicked the stop button");
        //alert($("#userId").val())
        //return;
        if ($("#userId").val().length > 0) {
            if (detector && detector.isRunning) {
                detector.removeEventListener();
                detector.stop();
                // $.post('http://localhost:5000/api/v1/regression',
                //     {
                //         faceParams: faceParams
                //     },
                //     function (data, status) {
                //         alert("Data: " + data + "\nStatus: " + status);
                //     });
                $.ajax({
                    // url: 'https://backend.in.ngrok.io/emotions',
                    url: 'http://localhost:3210/emotions',
                    type: 'POST',
                    data: JSON.stringify({
                        faceParams: faceParams,
                        demography: demography,
                        userId: $('#userId').val()
                    }),
                    contentType: 'application/json; charset=utf-8',
                    success: function (data) {
                        console.log(data);
                        alert(JSON.stringify(data))
                        $('#score').html(data.mean)
                    },
                })
            }
        } else {
            alert("Please enter the user ID")
        }
    };

    //function executes when the Reset button is pushed.
    function onReset() {
        log('#logs', "Clicked the reset button");
        if (detector && detector.isRunning) {
            detector.reset();

            $('#results').html("");
        }
    };

    // var detector = null; 
    // $(document).ready(function(){ 
    //     // SDK Needs to create video and canvas nodes in the DOM in order to function // Here we are adding those nodes a predefined div. 
    //     var divRoot = $("#affdex_elements")[0];
    // })
</script>

<!-- <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script> -->

</html>